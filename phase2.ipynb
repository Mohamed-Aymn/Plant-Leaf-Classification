{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "tgv2OFn38Oho"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the _Output directory\n",
        "input_directory = \"/content/drive/MyDrive/PlantClass/segmented_output\"\n",
        "\n",
        "# Initialize the images array\n",
        "images = []\n",
        "\n",
        "# Iterate through each folder in the _Output directory\n",
        "for folder_name in os.listdir(input_directory):\n",
        "    folder_path = os.path.join(input_directory, folder_name)\n",
        "\n",
        "    # Ensure it's a directory\n",
        "    if os.path.isdir(folder_path):\n",
        "        # List to hold images for this folder\n",
        "        folder_images = []\n",
        "\n",
        "        # Iterate through each file in the folder\n",
        "        for file in os.listdir(folder_path):\n",
        "            file_path = os.path.join(folder_path, file)\n",
        "\n",
        "            # Check if the file is an image (we'll assume all files are images)\n",
        "            if os.path.isfile(file_path):\n",
        "                # Read the image in grayscale\n",
        "                image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "                # Add the image to the list if it's successfully read\n",
        "                if image is not None:\n",
        "                    folder_images.append({\n",
        "                        \"image_name\": file,\n",
        "                        \"image\": image\n",
        "                    })\n",
        "\n",
        "        # If the folder contains images, append the folder object to the images array\n",
        "        if folder_images:\n",
        "            images.append({\n",
        "                \"folder_name\": folder_name,\n",
        "                \"images\": folder_images\n",
        "            })\n"
      ],
      "metadata": {
        "id": "q6awQRWb9Yvd"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to process each image and extract features\n",
        "def extract_features(image_data, folder_name):\n",
        "    \"\"\"\n",
        "    Extract features from a given image.\n",
        "    Returns a dictionary containing the features.\n",
        "    \"\"\"\n",
        "    # Get the image and its name\n",
        "    image_name = image_data[\"image_name\"]\n",
        "    image = image_data[\"image\"]\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contour = max(contours, key=cv2.contourArea) if contours else None\n",
        "\n",
        "    if contour is not None:\n",
        "        # Region Features\n",
        "        area = cv2.contourArea(contour)\n",
        "        perimeter = cv2.arcLength(contour, True)\n",
        "        circularity = (4 * np.pi * area) / (perimeter ** 2) if perimeter != 0 else 0\n",
        "        convex_hull = cv2.convexHull(contour)\n",
        "        convex_perimeter = cv2.arcLength(convex_hull, True)\n",
        "        convexity = convex_perimeter / perimeter if perimeter != 0 else 0\n",
        "        compactness = (perimeter ** 2) / area if area != 0 else 0\n",
        "\n",
        "        # Moments\n",
        "        moments = cv2.moments(image)\n",
        "        hu_moments = cv2.HuMoments(moments).flatten()\n",
        "\n",
        "        # Combine all features into a dictionary\n",
        "        feature_dict = {\n",
        "            \"Class\": folder_name,\n",
        "            \"Image_Name\": image_name,\n",
        "            \"Area\": area,\n",
        "            \"Perimeter\": perimeter,\n",
        "            \"Circularity\": circularity,\n",
        "            \"Convexity\": convexity,\n",
        "            \"Compactness\": compactness,\n",
        "        }\n",
        "\n",
        "        # Add Hu Moments to the dictionary\n",
        "        for i, moment in enumerate(hu_moments):\n",
        "            feature_dict[f'Hu_Moment_{i+1}'] = moment\n",
        "\n",
        "        return feature_dict\n",
        "\n",
        "    return None  # Return None if no valid contour is found"
      ],
      "metadata": {
        "id": "Ag0QEiwX9plW"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features for all images\n",
        "features = []\n",
        "\n",
        "for folder_data in images:\n",
        "    folder_name = folder_data[\"folder_name\"]\n",
        "    folder_images = folder_data[\"images\"]\n",
        "\n",
        "    for image_data in folder_images:\n",
        "        # Extract features for each image\n",
        "        feature = extract_features(image_data, folder_name)\n",
        "        if feature:\n",
        "            features.append(feature)\n",
        "\n",
        "# Convert to pandas DataFrame\n",
        "features_df = pd.DataFrame(features)\n",
        "\n",
        "# Save to CSV\n",
        "output_csv = \"/content/drive/MyDrive/PlantClass/features.csv\"\n",
        "features_df.to_csv(output_csv, index=False)\n",
        "print(f\"Feature extraction complete. Features saved to {output_csv}.\")\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(features_df.head)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHZ9mAwe-u-E",
        "outputId": "a1819175-cc20-4033-8009-a557693bddfe"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature extraction complete. Features saved to /content/drive/MyDrive/PlantClass/features.csv.\n",
            "<bound method NDFrame.head of                         Class     Image_Name     Area    Perimeter  \\\n",
            "0     Alstonia_Scholaris_(P2)  0003_0024.JPG  12659.5  1697.010438   \n",
            "1     Alstonia_Scholaris_(P2)  0003_0161.JPG  39112.5  2649.975070   \n",
            "2     Alstonia_Scholaris_(P2)  0003_0118.JPG  61646.0  3862.260550   \n",
            "3     Alstonia_Scholaris_(P2)  0003_0061.JPG  38550.5  3876.964086   \n",
            "4     Alstonia_Scholaris_(P2)  0003_0062.JPG  43666.5  2886.994403   \n",
            "...                       ...            ...      ...          ...   \n",
            "1735               Jamun_(P5)  0005_0137.JPG  65495.5  2998.734518   \n",
            "1736               Jamun_(P5)  0005_0125.JPG  68608.0  2966.526366   \n",
            "1737               Jamun_(P5)  0005_0007.JPG  36318.5  3268.842161   \n",
            "1738               Jamun_(P5)  0005_0051.JPG  35332.5  2363.156748   \n",
            "1739               Jamun_(P5)  0005_0075.JPG  63958.5  4691.242428   \n",
            "\n",
            "      Circularity  Convexity  Compactness  Hu_Moment_1   Hu_Moment_2  \\\n",
            "0        0.055240   0.360040   227.484847     0.001824  2.577140e-06   \n",
            "1        0.069991   0.366685   179.542803     0.001102  3.064511e-07   \n",
            "2        0.051932   0.322140   241.979310     0.001189  7.093116e-07   \n",
            "3        0.032230   0.274410   389.900274     0.001323  1.082526e-06   \n",
            "4        0.065836   0.361474   190.872561     0.001147  8.825576e-07   \n",
            "...           ...        ...          ...          ...           ...   \n",
            "1735     0.091526   0.355876   137.298115     0.001393  8.723567e-07   \n",
            "1736     0.097969   0.398333   128.268987     0.000845  3.121869e-07   \n",
            "1737     0.042712   0.313519   294.211740     0.001078  6.571358e-07   \n",
            "1738     0.079506   0.320056   158.055892     0.000707  5.684567e-08   \n",
            "1739     0.036520   0.230404   344.094304     0.000920  1.532394e-07   \n",
            "\n",
            "       Hu_Moment_3   Hu_Moment_4   Hu_Moment_5   Hu_Moment_6   Hu_Moment_7  \n",
            "0     4.551128e-10  3.873898e-10  1.626395e-19  5.632237e-13 -2.608682e-21  \n",
            "1     7.103458e-11  2.428548e-10 -2.198080e-20  7.253913e-14  2.311465e-20  \n",
            "2     6.772024e-11  7.579738e-13 -4.134162e-24 -6.134090e-16  3.521240e-24  \n",
            "3     2.442289e-10  1.040054e-10  1.640164e-20  1.069013e-13 -2.398588e-21  \n",
            "4     1.038397e-10  6.615136e-11  5.478738e-21  6.211386e-14 -2.068683e-22  \n",
            "...            ...           ...           ...           ...           ...  \n",
            "1735  3.607563e-11  3.957908e-11 -1.037370e-21 -2.907888e-14 -1.077303e-21  \n",
            "1736  8.587776e-12  6.971501e-13  6.738592e-26 -8.139537e-17  1.704475e-24  \n",
            "1737  2.585125e-11  1.548404e-11  3.018236e-22  1.144562e-14 -6.980221e-23  \n",
            "1738  6.971014e-12  2.372093e-12  4.335686e-24  5.488364e-16 -8.616634e-24  \n",
            "1739  1.164921e-11  1.231033e-11  4.206066e-23  4.042346e-15 -1.412911e-22  \n",
            "\n",
            "[1740 rows x 14 columns]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(features_df, test_size=0.2, random_state=42):\n",
        "    # Separate features and labels\n",
        "    X = features_df.drop(columns=['Class', 'Image_Name'])  # Drop non-feature columns\n",
        "    y = features_df[\"Class\"]  # Target class labels\n",
        "\n",
        "    # Split the data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n"
      ],
      "metadata": {
        "id": "iTbIpONFEPZ_"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the split function\n",
        "X_train, X_test, y_train, y_test = split_data(features_df)\n",
        "\n",
        "# Verify the results\n",
        "print(f\"Training set size: {len(X_train)}\")\n",
        "print(f\"Testing set size: {len(X_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ws8UMHqhEX3Z",
        "outputId": "eb312fab-3a11-419b-b7f2-698ea482a062"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 1392\n",
            "Testing set size: 348\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the classifier\n",
        "classifier = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Train the classifier\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on the test set\n",
        "y_pred = classifier.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")\n",
        "joblib.dump(classifier, \"/content/drive/MyDrive/PlantClass/trained_model.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OHt8OihFtZe",
        "outputId": "0a6937fa-3f31-4046-f2b0-2825b6c7c3e6"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.62\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/PlantClass/trained_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_image(image_path, classifier, feature_columns):\n",
        "    # Extract features from the image using your `extract_features` function\n",
        "    image_data = {\"image_name\": \"input_image\", \"image\": cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)}\n",
        "    folder_name = \"Unknown\"  # Placeholder for class\n",
        "\n",
        "    feature_dict = extract_features(image_data, folder_name)\n",
        "    if feature_dict is None:\n",
        "        raise ValueError(\"Failed to extract features from the image.\")\n",
        "\n",
        "    # Convert the feature dictionary to a DataFrame with the same feature names as training\n",
        "    feature_vector = pd.DataFrame([feature_dict], columns=feature_columns)\n",
        "\n",
        "    # Predict the class\n",
        "    predicted_class = classifier.predict(feature_vector)[0]\n",
        "    return predicted_class\n"
      ],
      "metadata": {
        "id": "yo-tjpV_Ltrd"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained classifier\n",
        "classifier = joblib.load(\"/content/drive/MyDrive/PlantClass/trained_model.pkl\")\n",
        "\n",
        "# Define the feature columns (as used during training)\n",
        "feature_columns = [\"Area\", \"Perimeter\", \"Circularity\", \"Convexity\", \"Compactness\"] + \\\n",
        "                  [f'Hu_Moment_{i+1}' for i in range(7)]\n",
        "\n",
        "# Provide the path to the input image\n",
        "image_path = \"/content/drive/MyDrive/PlantClass/segmented_output/Chinar_(P11)/0011_0033.JPG\"\n",
        "\n",
        "predicted_class = classify_image(image_path, classifier, feature_columns)\n",
        "print(f\"The predicted class for the input image is: {predicted_class}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2egqlHGvLywu",
        "outputId": "c07164de-b258-4483-86e8-cb8cb6f4ddec"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted class for the input image is: Chinar_(P11)\n"
          ]
        }
      ]
    }
  ]
}