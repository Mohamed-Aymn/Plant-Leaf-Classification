{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "tgv2OFn38Oho"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the _Output directory\n",
        "input_directory = \"/content/drive/MyDrive/PlantClass/segmented_output\"\n",
        "\n",
        "# Initialize the images array\n",
        "images = []\n",
        "\n",
        "# Iterate through each folder in the _Output directory\n",
        "for folder_name in os.listdir(input_directory):\n",
        "    folder_path = os.path.join(input_directory, folder_name)\n",
        "\n",
        "    # Ensure it's a directory\n",
        "    if os.path.isdir(folder_path):\n",
        "        # List to hold images for this folder\n",
        "        folder_images = []\n",
        "\n",
        "        # Iterate through each file in the folder\n",
        "        for file in os.listdir(folder_path):\n",
        "            file_path = os.path.join(folder_path, file)\n",
        "\n",
        "            # Check if the file is an image (we'll assume all files are images)\n",
        "            if os.path.isfile(file_path):\n",
        "                # Read the image in grayscale\n",
        "                image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "                # Add the image to the list if it's successfully read\n",
        "                if image is not None:\n",
        "                    folder_images.append({\n",
        "                        \"image_name\": file,\n",
        "                        \"image\": image\n",
        "                    })\n",
        "\n",
        "        # If the folder contains images, append the folder object to the images array\n",
        "        if folder_images:\n",
        "            images.append({\n",
        "                \"folder_name\": folder_name,\n",
        "                \"images\": folder_images\n",
        "            })"
      ],
      "metadata": {
        "id": "q6awQRWb9Yvd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to process each image and extract features\n",
        "def extract_features(image_data, folder_name):\n",
        "    \"\"\"\n",
        "    Extract features from a given image.\n",
        "    Returns a dictionary containing the features.\n",
        "    \"\"\"\n",
        "    # Get the image and its name\n",
        "    image_name = image_data[\"image_name\"]\n",
        "    image = image_data[\"image\"]\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contour = max(contours, key=cv2.contourArea) if contours else None\n",
        "\n",
        "    if contour is not None:\n",
        "        # Region Features\n",
        "        area = cv2.contourArea(contour)\n",
        "        perimeter = cv2.arcLength(contour, True)\n",
        "        circularity = (4 * np.pi * area) / (perimeter ** 2) if perimeter != 0 else 0\n",
        "        convex_hull = cv2.convexHull(contour)\n",
        "        convex_perimeter = cv2.arcLength(convex_hull, True)\n",
        "        convexity = convex_perimeter / perimeter if perimeter != 0 else 0\n",
        "        compactness = (perimeter ** 2) / area if area != 0 else 0\n",
        "\n",
        "        # Moments\n",
        "        moments = cv2.moments(image)\n",
        "        hu_moments = cv2.HuMoments(moments).flatten()\n",
        "\n",
        "        # Combine all features into a dictionary\n",
        "        feature_dict = {\n",
        "            \"Class\": folder_name,\n",
        "            \"Image_Name\": image_name,\n",
        "            \"Area\": area,\n",
        "            \"Perimeter\": perimeter,\n",
        "            \"Circularity\": circularity,\n",
        "            \"Convexity\": convexity,\n",
        "            \"Compactness\": compactness,\n",
        "        }\n",
        "\n",
        "        # Add Hu Moments to the dictionary\n",
        "        for i, moment in enumerate(hu_moments):\n",
        "            feature_dict[f'Hu_Moment_{i+1}'] = moment\n",
        "\n",
        "        return feature_dict\n",
        "\n",
        "    return None  # Return None if no valid contour is found"
      ],
      "metadata": {
        "id": "Ag0QEiwX9plW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features for all images\n",
        "features = []\n",
        "\n",
        "for folder_data in images:\n",
        "    folder_name = folder_data[\"folder_name\"]\n",
        "    folder_images = folder_data[\"images\"]\n",
        "\n",
        "    for image_data in folder_images:\n",
        "        # Extract features for each image\n",
        "        feature = extract_features(image_data, folder_name)\n",
        "        if feature:\n",
        "            features.append(feature)\n",
        "\n",
        "# Convert to pandas DataFrame\n",
        "features_df = pd.DataFrame(features)\n",
        "\n",
        "# Save to CSV\n",
        "output_csv = \"/content/drive/MyDrive/PlantClass/features.csv\"\n",
        "features_df.to_csv(output_csv, index=False)\n",
        "print(f\"Feature extraction complete. Features saved to {output_csv}.\")\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(features_df.head)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHZ9mAwe-u-E",
        "outputId": "f4293189-2b58-4400-d6e5-0f92e607176d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature extraction complete. Features saved to /content/drive/MyDrive/PlantClass/features.csv.\n",
            "<bound method NDFrame.head of                         Class     Image_Name     Area    Perimeter  \\\n",
            "0     Alstonia_Scholaris_(P2)  0003_0132.JPG  74223.0  3463.677730   \n",
            "1     Alstonia_Scholaris_(P2)  0003_0084.JPG  21896.5  3611.435088   \n",
            "2     Alstonia_Scholaris_(P2)  0003_0072.JPG  16228.5  1716.324145   \n",
            "3     Alstonia_Scholaris_(P2)  0003_0069.JPG  28334.5  2384.612591   \n",
            "4     Alstonia_Scholaris_(P2)  0003_0134.JPG  49997.5  2858.970017   \n",
            "...                       ...            ...      ...          ...   \n",
            "7648               Basil_(P8)  0008_0143.JPG  13151.0  1063.248904   \n",
            "7649               Basil_(P8)  0008_0146.JPG  22740.0  1466.836778   \n",
            "7650               Basil_(P8)  0008_0147.JPG  27115.0  1603.405319   \n",
            "7651               Basil_(P8)  0008_0145.JPG  24085.5  1620.334252   \n",
            "7652               Basil_(P8)  0008_0148.JPG  27658.5  1553.304815   \n",
            "\n",
            "      Circularity  Convexity  Compactness  Hu_Moment_1   Hu_Moment_2  \\\n",
            "0        0.077745   0.346576   161.635388     0.000919  2.801474e-07   \n",
            "1        0.021097   0.295412   595.641468     0.002781  6.192127e-06   \n",
            "2        0.069229   0.372909   181.518229     0.001111  7.833335e-07   \n",
            "3        0.062617   0.330466   200.687403     0.001004  6.019215e-07   \n",
            "4        0.076867   0.355221   163.482365     0.000819  2.511931e-07   \n",
            "...           ...        ...          ...          ...           ...   \n",
            "7648     0.146184   0.437562    85.962910     0.000746  1.528490e-07   \n",
            "7649     0.132812   0.418622    94.617860     0.000717  1.018426e-07   \n",
            "7650     0.132536   0.409712    94.814996     0.000744  1.599143e-07   \n",
            "7651     0.115281   0.397789   109.006792     0.000776  1.710677e-07   \n",
            "7652     0.144054   0.425491    87.233792     0.000745  1.561706e-07   \n",
            "\n",
            "       Hu_Moment_3   Hu_Moment_4   Hu_Moment_5   Hu_Moment_6   Hu_Moment_7  \n",
            "0     5.132801e-11  7.779374e-12  1.393392e-22  4.021640e-15 -6.891795e-23  \n",
            "1     4.901326e-09  3.885692e-09  1.694619e-17  9.664975e-12  6.163940e-19  \n",
            "2     2.616097e-10  1.466084e-10  2.867552e-20  1.283685e-13  1.449005e-21  \n",
            "3     1.973026e-11  1.004762e-11  1.405455e-22  7.211512e-15  1.613805e-23  \n",
            "4     5.037161e-12  1.861717e-12  5.661648e-24  9.312172e-16  6.700520e-25  \n",
            "...            ...           ...           ...           ...           ...  \n",
            "7648  2.044486e-11  2.697821e-12  1.996601e-23  1.047843e-15 -1.673707e-24  \n",
            "7649  2.639692e-11  2.936520e-12  2.554908e-23  9.151407e-16  3.958372e-24  \n",
            "7650  1.939567e-12  2.153683e-13  1.333067e-25  7.975135e-17 -4.005888e-26  \n",
            "7651  5.215248e-11  6.259256e-12  8.909028e-23  1.861431e-15 -6.965710e-23  \n",
            "7652  1.290354e-11  1.592062e-12  7.215615e-24  6.286255e-16  7.118620e-26  \n",
            "\n",
            "[7653 rows x 14 columns]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(features_df, test_size=0.2, random_state=42):\n",
        "    # Separate features and labels\n",
        "    X = features_df.drop(columns=['Class', 'Image_Name'])  # Drop non-feature columns\n",
        "    y = features_df[\"Class\"]  # Target class labels\n",
        "\n",
        "    # Split the data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n"
      ],
      "metadata": {
        "id": "iTbIpONFEPZ_"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the split function\n",
        "X_train, X_test, y_train, y_test = split_data(features_df)\n",
        "\n",
        "# Verify the results\n",
        "print(f\"Training set size: {len(X_train)}\")\n",
        "print(f\"Testing set size: {len(X_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ws8UMHqhEX3Z",
        "outputId": "3dbb06d5-1460-4244-cc2a-35a3ec43e13b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 6122\n",
            "Testing set size: 1531\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the classifier\n",
        "classifier = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Train the classifier\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on the test set\n",
        "y_pred = classifier.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OHt8OihFtZe",
        "outputId": "83a2fba1-ae33-41b4-d873-953d0d1a955d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.89\n"
          ]
        }
      ]
    }
  ]
}